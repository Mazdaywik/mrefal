====================================================================================================
  [TOTHINK] Упрощение структуры Lexer'а и Parser'а
====================================================================================================

  [TODO] 12.02.2008 - 20:14:38,84

  Возможно, стоит переписать лексический анализатор так, чтобы он на входе имел не имя файла, а
сразу всё его содержимое, а на выходе выдавал лексическую свёртку. Точно также можно изменить и син-
таксический анализатор: чтобы он принимал на входе лексическую свёртку. Это позволит (а) упростить
их структуру, (б) можно написать генератор кода для Lexer'а, что упростит его дальнейшую разработку,
(в) сделает соответствующие модули "функционально чистыми". Последний пункт красив идеологически, но
в данной версии Модульного Рефала он бессмысленен, поскольку никаких преимуществ ни по быстродейст-
вию, ни по качеству генерируемого кода не даёт.
  Сегодняшний вариант сделан из соображений экономии памяти: без лишних затрат памяти он может спо-
койно обработать файл, содержащий мегабайт пустых строк или мегабайт строк с одной точкой с запятой.
Однако, это вырожденный случай. При работе линковщика в память загружаются целиком rout-файлы, кото-
рые по объёму больше чем соответствующие им модули исходного текста, -- и ничего, работает.
  В заголовке я написал "продумать". Это значит, что если нет острой необходимости, то менять ниче-
го не надо. На сегодняшний день lexer и parser написаны достаточно культурно в плане кода, как мне
кажется, почти без ошибок (хотя недавно одну исправил).
----------------------------------------------------------------------------------------------------
  [TODO] 01.02.2009 - 21:42:25,09

  При создании нового синтаксиса, который будет поддерживать более широкие возможности (хотя бы
действия в смысле Рефала 6 и Рефала 7; функции, локальные для других функций и др.) я буду исполь-
зовать именно такие способы лексического и синтаксического анализа (загрузка файла целиком в память
с дальнейшим получением лексической и синтаксической свёртки; использование генератора лексического
анализатора, хотя бы подгонка генератора для Simple Refal; сначала строить синтаксическое дерево
КС-грамматики, затем строить IModule).
  Но, как сказано выше (в журнале), в задачу выхода версии 0.2 не входит ни изменение синтасиса,
ни существенная переработка Lexer'а и Parser'а.
----------------------------------------------------------------------------------------------------
  [TODO] 01.05.2010 - 19:30:19,45

  (Ревизия 01.05.2010) Не требуется для выпуска версии 0.2.
----------------------------------------------------------------------------------------------------
  [TODO] 25.07.2010 - 12:33:59,02

  (Ревизия 25.07.2010) Не требуется для выпуска версии 0.2.
----------------------------------------------------------------------------------------------------
  [RENAME] 07.09.2010 - 23:30:08,46

  Old name is "[TODO] Продумать упрощение структуры Lexer'а и Parser'а"
  """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
----------------------------------------------------------------------------------------------------
  [TOTHINK] 07.09.2010 - 23:30:08,46

  Удалено слово "продумать" ("обдумать") из заголовка, сменён тег с TODO на TOTHINK. (Переименова-
ние было проведено при первой возможности — сразу после того, как был введён тег RENAME.)
----------------------------------------------------------------------------------------------------
  [TOTHINK] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Скорее всего, интерфейс лексического анализатора пока видоизменяться не будет. Но подход
к семантической проверке и интерфейсу IModule может быть изменён: новый синтаксис со вложенными
функциями плохо ложится на текущую модель с одномерным списком функций в IModule.


====================================================================================================
  [TOTHINK] Двухуровневая структура синтаксического анализатора
====================================================================================================

  [TODO] 22.09.2008 - 23:27:35,87

  Сейчас компилятором по исходному коду создаётся "сырое" промежуточное представление IModule, в
котором затем производится разрешение вызовов. Новая идея такая. Вместо "сырого" IModule порождать
тупо структуру, близкую к синтаксическому дереву модуля, а уже затем на её основе порождать IModule
с разрешением внешних ссылок.
  Можно в синтаксисе затребовать, чтобы все импортируемые модули были объявлены перед их использо-
ванием. Это бы упростило создание "однопроходного" компилятора в дальнейшем, если такая дикая мысль
ко мне придёт.
----------------------------------------------------------------------------------------------------
  [TODO] 01.02.2009 - 21:42:25,09

  При создании нового синтаксиса, который будет поддерживать более широкие возможности (хотя бы
действия в смысле Рефала 6 и Рефала 7; функции, локальные для других функций и др.) я буду исполь-
зовать именно такие способы лексического и синтаксического анализа (загрузка файла целиком в память
с дальнейшим получением лексической и синтаксической свёртки; использование генератора лексического
анализатора, хотя бы подгонка генератора для Simple Refal; сначала строить синтаксическое дерево
КС-грамматики, затем строить IModule).
  Но, как сказано выше (в журнале), в задачу выхода версии 0.2 не входит ни изменение синтасиса,
ни существенная переработка Lexer'а и Parser'а.
----------------------------------------------------------------------------------------------------
  [TODO] 01.05.2010 - 19:30:19,45

  (Ревизия 01.05.2010) Не требуется для выпуска версии 0.2.
  Имеющаяся структура компилятора на данный момент работает достаточно стабильно и не вызывает не-
удобств в использовании. Переделка без изменения внешнего поведения никак не повлияет на возможнос-
ти версии 0.2, но может существенно оттянуть сроки выпуска этой версии.
----------------------------------------------------------------------------------------------------
  [TODO] 25.07.2010 - 12:33:59,02

  (Ревизия 25.07.2010) Не требуется для выпуска версии 0.2.
----------------------------------------------------------------------------------------------------
  [RENAME] 07.09.2010 - 23:30:08,46

  Old name is "[TODO] Продумать двухуровневую структуру синтаксического анализа"
  """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
----------------------------------------------------------------------------------------------------
  [TOTHINK] 07.09.2010 - 23:30:08,46

  Удалено слово "продумать" ("обдумать") из заголовка, сменён тег с TODO на TOTHINK. (Переименова-
ние было проведено при первой возможности — сразу после того, как был введён тег RENAME.)
----------------------------------------------------------------------------------------------------
  [TOTHINK] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  При дальнейшем развитии синтаксиса неизбежно возникнет вопрос адаптации имеющихся структур
данных к новым синтаксическим конструкциям. Тогда же этот вопрос и будет решён.


====================================================================================================
  [TODO] Блоки $INIT и $FINAL
====================================================================================================

  [TODO] 23.09.2008 - 12:50:36,46

  Вместо использования функций с именами Init и Final предполагается использовать блоки с примерно
таким синтаксисом:
  InitBlock = '$INIT' ResultExpression ';' .
  FinalBlock = '$FINAL' ResultExpression ';' .
  Мотивация. Функции $INIT и $FINAL, безусловно нужные для инициализации и финализации модулей с по-
бочными эффектами, обладают рядом недостатков. В текущей версии компилятора их всегда можно вызвать
из пользовательского кода (запрета на это нет, хотя поведение считается неопределённым). Функции
всегда требуют пустого аргумента на входе, хотя не запрещается написать что-то вроде
  $ENTRY Init {
    A = <DoSomething>;
    s.X (e.Y) = <DoSomethingElse>;
  }
что никакой полезной нагрузки не несёт, более того, подобная функция обязательно обрушит программу.
К тому же, для подобных функций приходится выделять особые зарезервированные имена (в частности,
нельзя создать АТД с подобными именами -- поведение не определено). Ведь изначально синтаксис Рефа-
ла 5 и так построен в расчёте на то, что происходит минимальное вторжение в область пользователь-
ских определений (зарезервирована только функция Go, с которой по соглашению начинается выполнение
программы, и, к сожалению, встроенные функции). В Модульном Рефале я избавился от встроенных функ-
ций, функцию Go устранять в обозримом будущем я не собираюсь. А вот устранить Init и Final вполне
реально.
  Новый синтаксис инициализации и финализации решает все вышеперечисленные проблемы: код инициали-
зации и финализации не может быть вызван пользователем (конечно, можно написать функцию, которую
можно вызвать и из кода инициализации, и из пользовательского кода -- но это будет осознанное про-
ектное решение); нет проблемы с необычными образцами -- образцов в новом синтаксисе нет в принципе;
не загромождается область пользовательских определений.
----------------------------------------------------------------------------------------------------
  [TODO] 01.02.2009 - 21:42:25,09

  Маловероятно, что я буду менять синтаксис до выхода версии 0.2. Однако, создание в промежуточном
представлении IModule поддержки блоков $INIT и $FINAL я считаю возможным. Такие блоки инициализации
и финализации будут присутствовать во всех модулях, особенность будет лишь в том, что в тех модулях,
в которых инициализация/финализация явно пользователем не задана, эти блоки будут пустыми. Это поз-
волит в линковщике обрабатывать модули унифицированным образом, и, возможно, упростит решение ошиб-
ки, связанные с финализаторами и MOS::Exit (см. соответствующую ERROR).
----------------------------------------------------------------------------------------------------
  [TODO] ‚в 21.04.2009 - 13:02:07.17

  Поддержка блоков $INIT и $FINAL в промежуточном представлении IModule реализована. Не смотря на
то, что текущая версия синтаксиса эти блоки не поддерживает, остальная часть компилятора (синтакси-
ческий анализатор, промежуточное представление, генераторы и компоновщики) эти блоки поддерживает.
  Помимо поддержки блоков инициализации и финализации, также поддерживается стартовый код для го-
ловного модуля. Синтаксический анализатор, при обнаружении в головном модуле функции $ENTRY Go или
в регулярном модуле функций $ENTRY Init и $ENTRY Final, добавляет в код точек входа (соотв. в стар-
товый код или код инициализации и финализации) вызовы этих функций. За счёт этого остальная часть
программы не зависит от имён этих функций (стартовой, инициализации и финализации), что существенно
упрощает её (при переработке совокупный код компоновщика back-end'а Рефала 5 уменьшился на один мо-
дуль, как раз и отвечающий за поиск функций с именами Go, Init и Final).
  А, собственно, поддержку блоков $INIT и $FINAL я оставляю как TODO, т.к. надеюсь их увидеть в сле-
дующей версии синтаксиса.
----------------------------------------------------------------------------------------------------
  [TODO] 01.05.2010 - 19:30:19,45

  (Ревизия 01.05.2010) Не требуется для выпуска версии 0.2.
  Синтаксис менять я не собираюсь, поэтому оставляю этот пункт в копилку идей.
----------------------------------------------------------------------------------------------------
  [TODO] 25.07.2010 - 12:33:59,02

  (Ревизия 25.07.2010) Как уже сказано, выпуск версии не подразумевает переработки синтаксиса отно-
сительно текущего состояния. Поэтому эти конструкции я сейчас внедрять не буду. Но сделаю их при
первой же существенной переделке синтаксиса.
----------------------------------------------------------------------------------------------------
  [RENAME] 07.09.2010 - 23:30:08,46

  Old name is "[TODO] Продумать блоки $INIT и $FINAL"
  """""""""""""""""""""""""""""""""""""""""""""""""""
----------------------------------------------------------------------------------------------------
  [TOTHINK] 07.09.2010 - 23:30:08,46

  Удалено слово "продумать" ("обдумать") из заголовка, сменён тег с TODO на TOTHINK. (Переименова-
ние было проведено при первой возможности — сразу после того, как был введён тег RENAME.)
----------------------------------------------------------------------------------------------------
  [TODO] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Во-первых, мораторий на изменение синтаксиса снят. А значит, можно добавить и блоки $INIT
и $FINAL. Но, для совместимости (c версией N−1) имеет смысл сохранить традиционную обработку
функций Init и Final, если конструкции нового синтаксиса в модуле отсутствуют.
  Во-вторых, есть несколько некорректная обработка инциализаторов и финализаторов в профиле C++/SR.
Проблема следующая: инициализатор (финализатор) каждого модуля порождает в поле зрения
инициализаторы всех вложенных модулей, но вызывает код инициализации (финализации) только когда
счётчик вызовов равен нулю. Такая схема позволяет обеспечить правильный порядок инициализации
(финализации) модулей, одновременно сохранив независимую раздельную трансляцию (профиль SR,
к примеру, вынужден генерировать дополнительный файл исходного текста, содержащий только
последовательность инциализации модулей и небольшой runtime-код).
  Но в коде есть недочёты. Во-первых, вызовы функций инициализации и финализации в поле зрения
помещаются всегда, но вызываются только когда это требуется (когда счётчик равен нулю) — когда
не надо, они просто не помещаются в стек вызовов. Из-за этого в дампе поля зрения скапливается
некоторое количество вызовов инициализаторов, которые ни разу не выполнились. Второй недочёт —
код инициализации каждого модуля вставляет вызовы кода инициализации импортируемых модулей,
те, в свою очередь — вызовы кода инициализации своих импортов, из-за чего один и тот же код
вызывается очень много раз. Так например, всего за время выполнения программы выполняется
13 444 113 шагов рефал-машины, внутри функции Go — 13 437 940 шага. Разница в 6173 шага — код
инициализации и финализации, что не мало. По времени это составляет 0,3 секунды на Pentium MMX.


====================================================================================================
  [TOTHINK] Написание комплексных тестов для библиотеки
====================================================================================================

  [TOTHINK] 07.01.2010 - 23:12:41,12

  Они нужны. Осознаю их необходимость, но сформулированных мыслей у меня нет.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 01.05.2010 - 19:30:19,45

  (Ревизия 01.05.2010) Не требуется для выпуска версии 0.2.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 25.07.2010 - 12:33:59,02

  (Ревизия 25.07.2010) Не требуется для выпуска версии 0.2.
  По хорошему, надо писать не только тесты (некоторый небольшой набор тестов у меня есть), но и
средства автоматического тестирования (например, скриптом) и эти средства периодически обновлять.
  Некоторым подобием автоматического теста у меня является большой скрипт пересборки: он пересоби-
рает весь компилятор каждым исполнимым файлом, созданным некоторым профилем, с каждым профилем, что
в некоторой степени гарантирует его корректность.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  В первую очередь нужно реализовать средства автоматического тестирования, а уже потом,
с их использованием, покрывать тестами и библиотеку, и компилятор. Сейчас у меня это в планах
не стоит, поэтому задача остаётся в статусе TOTHINK.


====================================================================================================
  [TOTHINK] Грамотная реализация библиотеки
====================================================================================================

  [TOTHINK] 10.07.2010 - 15:35:46,55

  В этой записи я хочу привести черновые мысли по поводу того, как следует организовать структуру
библиотеки Модульного Рефала.
  Модулями, предоставляющими интерфейс прикладного программирования (API) библиотеки являются моду-
ли, находящиеся в пакетах Std, Platform и BackEnd.
  Пакет Std содержит набор модулей, доступных под любой целевой платформой в широком смысле, т.е.
под любой операционной системой, под которую реализован Модульный Рефал (Windows, разновидности
POSIX) и с любым back-end'ом, способным создать исполняемые файлы (генерация кода под Си++, .NET,
RASL Рефала 5 и, возможно, какие-нибудь другие).
  Функции модулей этого пакета должны быть безопасны, т.е. не могут разрушить инварианты поля зре-
ния и вычислительной среды. Эти модули, скорее всего, написаны на Модульном Рефале и используют
средства модулей двух других пакетов.
  Пакет Platform предоставляет (не обязательно в полном объёме) средства API целевой платформы, при
этом конкретной платформе может соответствовать один или несколько модулей.
  Например, могут предостаставляться следующие возможности:
  * модуль Platform::CRuntime предоставляет средства API языка Си, например, потоки ввода-вывода из
<stdio.h> или функции из библиотеки <stdlib.h>;
  * модуль Platform::Windows предоставтяет такие возможности операционной системы, как запуск новых
процессов (функцией CreateProcess), получение атрибутов файла, характерных для Windows и т.д.;
  * модуль Platform::Posix предоставляет возможности, аналогичные возможностям модуля Platform::
Windows, хотя имена функций и их семантика могут отличаться (CreateProcess принимает имя исполняе-
мого файла и командную строку, Exec --- имя исполнимого файла и набор аргументов командной строки);
  * Platform::DotNET предоставляет свои средства;
  * Platform::Refal5 обеспечивает непосредственный вызов встроенных функций целевого языка и др.
  Модули могут как писаться на целевом языке, так и на Модульном Рефале, например, для обеспечения
более удобного интерфейса.
  Функции этого модуля не обязаны быть безопасными, они могут создавать некорректные элементы в по-
ле зрения, а также нарушать прочие инварианты вычислительной среды. Так например, Platform::Refal5
может предоставлять функции Explode, Implode и доступа к копилке, что может переломать костыли, не-
обходимые для компиляции Модульного Рефала в Рефал 5.
  Пакет BackEnd предоставляет возможности, характерные для рассматриваемого способа создания испол-
нимых файлов, не зависящих или слабо зависящих от конкретной операционной системы и не являющимися
элементами API целевой платформы.
  В качестве примера могут быть выделены следующие:
  * при компиляции в векторное или векторно-списковое представление могут предоставляться эффектив-
ные функции для получения длины выражения или N-го терма в выражении;
  * может предоставляться информация о текущем состоянии среды выполнения, такая как объём выделен-
ной памяти или число шагов;
  * легковесные потоки и управление ими;
  * принудительный вызов сборщика мусора;
  * работа с продолжениями (continuations) и другие.
  Аналогично, эти модули тоже могут писаться как на целевом языке, так и на Модульном Рефале.
  Аналогично, эти модули тоже не обязаны быть безопасными, даже более того, некоторые возможности
должны быть потенциально опасными, если они при этом являются полезными.
  Предполагается, что с использованием только модулей из пакета Std можно написать переносимую
между любыми целевыми платформами и способами компиляции. Кроме того, также предполагается, что
программист может и не пользоваться пакетом Std, т.к. пакеты должны Platform и BackEnd предостав-
лять те же средства, только в менее безопасном и менее переносимом виде.
  Следует обдумать вопрос: можно ли внутри Std предоставлять абстрагированные от конкретной платфор-
мы и способа компиляции возможности, доступные не во всех варинтах.
  Это TOTHINK оставляет открытым внутреннюю организацию библиотеки, т.е. наличие модулей во всевоз-
можных пакетах с префиксом Core (как сейчас это сделано), которые используются для упрощения пере-
носа библиотеки между разными платформами и способами компиляции.
  Это не приоритетная (для версии 0.2) задача, т.к. требует коренной переработки библиотеки, вклю-
чая интерфейс, т.е. займёт уйму времени. Поэтому это TODO я даже не снабдил префиксом СМКиРФ.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 25.07.2010 - 12:33:59,02

  (Ревизия 25.07.2010) Не требуется для выпуска версии 0.2, т.к. текущая версия библиотеки уже не-
плоха и вполне соответствует возможностям синтаксиса языка.
  С точки зрения грамотной реализации, текущая библиотека соответствует варианту пакета Std, но без
префикса Std и без альтернатив (Platform и BackEnd).
  Для выпуска публичной версии также не требуется, т.к. публичную версию вполне можно выпустить и с
текущей реализацией библиотеки.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Идея интересная, к ней следует стремиться. Но пока не актуально. Библиотеку лучше развивать
исходя из потребностей, и, время от времени, при мажорных релизах (до выпуска версии 1.0) делать
её рефакториг. Сейчас потребности перерабатывать библиотеку нет, но как часть генерального плана
развития данную задачу следует оставить.


====================================================================================================
  [TODO] НД: Написание текста документации
====================================================================================================

  [TODO] 18.10.2010 - 16:14:47,28

  Требуется написать документацию к компиляторам и языкам Модульного и Простого Рефалов в текущей
реализации. Документация должна включать в себя следующие пункты:
  1 Описание текущей версии языка Модульный Рефал без рассмотрения особенностей конкретной реали-
зации. Включает в себя синтаксис и семантику Рефала, концепцию модульности.
  2 Описание текущей версии компилятора Модульного Рефала: представление модулей в виде исходных
и промежуточных файлов, компиляция, компоновка, расположение файлов модулей.
  3 Описание текущей версии языка Простого Рефала, при этом следует акцентировать внимание на том,
что ряд возможностей (идентификаторы, статические ящики) добавлены для совместимости с Модульным
Рефалом. Поскольку семантика управляющих конструкций Модульного и Простого Рефалов во многом сход-
ны, то их можно рассмотреть бегло.
  4 Описание текущей реализации Простого Рефала в Си++, рассмотрение интерфейса с языком Си++.
  5 Рассмотрение back-end'ов реализации Модульного Рефала, написание библиотечных модулей для
back-end'ов C++/SR и SR.
  6 (Приложение) Установка реализации Модульного Рефала на компьютер.
  7 (Приложение) Установка реализации Простого Рефала на компьютер.
----------------------------------------------------------------------------------------------------
  [RENAME] 18.12.2015 - 16:11:11,60

  Old name is "[TODO] ВПВ: НД: Написание текста документации"
  """""""""""""""""""""""""""""""""""""""""""""""""""""""""""
----------------------------------------------------------------------------------------------------
  [TODO] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Проект Простого Рефала теперь развивается независимо от Модульного Рефала, соответственно,
документация к нему пишется независимо. А документацию к Модульному Рефалу писать надо. Следствие:
пункты 3 и 4 исключаются, остальное пока неизменно.
  Задача переименована, поскольку написание документации теперь более не входит в выпуск публичной
версии. Подробности в задаче, посвящённой выпуску публичной версии.


====================================================================================================
  [TOTHINK] Средство автоматической установки
====================================================================================================

  [TOTHINK] 05.11.2010 - 21:36:08,97

  Следует продумать способ установки компиляторов на диск компьютера. Возможные варианты для
платформы Windows:
  1. Использование make-файлов.
  2. Использование специализированных средств установки типа пакетов MSI.
  3. Написание кустарного инсталлятора на базе sfx-архивов WinRAR и пакетных файлов.
----------------------------------------------------------------------------------------------------
  [RENAME] 18.12.2015 - 16:11:11,60

  Old name is "[TOTHINK] ВПВ: Средство автоматической установки"
  """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""
----------------------------------------------------------------------------------------------------
  [TOTHINK] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Задача актуальна, но не приоритетна. В рамках проекта Простого Рефала сейчас планируется создание
отдельного репозитория, в котором будут храниться полускомпилированные исходники компилятора(файлы
на C++). Сам репозиторий в некотором смысле может играть роль инсталлятора: клонирование и сборка
исполнимых файлов должны будут создавать готовый к использованию дистрибутив. Опыт работы с таким
репозиторием будет учтён в текущей задаче.
  Задача переименована, поскольку создание инсталлятора теперь более не входит в выпуск публичной
версии. Подробности в задаче, посвящённой выпуску публичной версии.


====================================================================================================
  [TODO] Написание документации (НД)
====================================================================================================

  [TODO] 18.10.2010 - 16:14:47,28

  Выпуск публичной версии компилятора требует написания документации: описания языка и описания
конктретной реализации. Поскольку предполагается распространение Модульного и Простого Рефалов
в одном дистрибутиве, документация должна включать в себя сведения об обоих диалектах.
  Отсюда две подзадачи:
  1 Написание "контента";
  2 Выбор способа представления контента.
----------------------------------------------------------------------------------------------------
  [TODO] 16.09.2012 - 11:13:49,96

  Сначала я предполагал размещать документацию на сайте blogspot, даже уже частично написал, однако,
к некоторому моменту я потерял интерес к этому процессу. В качестве представления этот способ
оказался не слишком удобен: данные хранятся на удалённом сервере, поэтому для редактирования надо
быть в онлайне, к тому же, необходимо логиниться на сайте.
  Недавно мне пришла в голову неплохая идея: можно писать документацию в формате docx/odt — с одной
стороны, это автоматически даёт возможность получить красиво отформатированный pdf, с другой —
формат представляет собой набор зазипованных xml’ек, который, при необходимости, относительно легко
распарсить, просто выбирая только теги с понятным содержимым, а остальные игнорируя.
  Преимущество формата docx — возможности форматирования Microsoft Word, которым я умею эффективно
пользоваться.
  Преимущество формата odt — кроссплатформенность и простота для парсинга (XML более ясный, чем
у Microsoft Word).
----------------------------------------------------------------------------------------------------
  [RENAME] 18.12.2015 - 16:11:11,60

  Old name is "[TODO] ВПВ: Написание документации (НД)"
  """""""""""""""""""""""""""""""""""""""""""""""""""""
----------------------------------------------------------------------------------------------------
  [TODO] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Идея с использованием файлов docx или odt и конвертером, например, в текстовый формат, имеет
тот недостаток, что разница между коммитами либо не отображается, либо отображается в довольно
неудобном виде.
  Более подходящий вариант — использование изначально текстового представления. Варианты:
  * Свой конвертер. Начинал писать, дело далеко не продвинулось. Велосипед, вероятно, тупиковый
путь.
  * TeX:
    (+) Красиво отформатированный, пригодный для публикации формат.
    (−) Высокий порог вхождения, т.е. мне потребуется изучать новую среду: LaTeX или Lyx.
    (−) Тяжёлые для чтения исходники.
  * Markdown:
    (+) Лёгкость в использовании, низкий порог вхождения.
    (+) Доступно множество редакторов, конверторов. (Ни одним ещё не пользовался, но список
на Википедии длинный.)
    (+) Исходники легко читать.
    (+) Если просто хранить в подпапке набор файлов в разметке Markdown с гиперссылками друг
на друга, то в web-интерфейсе GitHub оно будет отображаться фактически как wiki-энциклопедия.
    (−) Чтобы сохранять читаемость исходников, нужно будет при редактировании каждый раз выравнивать
длины строк. Это снижает сопровождаемость (хотя в ряде текстовых редакторов (Vim, Emacs) есть
функция выравнивания строк). Соответственно, различия между коммитами будут включать много замен
строк, даже если изменилось только несколько слов. В TeX такая проблема тоже присутствует,
но исходники не предназначены для чтения.
    (−) Для ввода типографских плюшек (длинные тире, кавычки-ёлочки, неразрывные пробелы) нужно
или использовать последовательности HTML (что засоряет текст), либо специальные раскладки
клавиатуры. Кроме того, неразрывные пробелы внешне неотличимы от обычных, что тоже создаёт проблемы.
  Так что задача пока остаётся открытой. Возможен вариант использования wiki, встроенной в GitHub.
  Задача переименована, поскольку написание документации теперь более не входит в выпуск публичной
версии. Подробности в задаче, посвящённой выпуску публичной версии.


====================================================================================================
  [TODO] Вложенные функции (ВФ)
====================================================================================================

  [TODO] 18.10.2010 - 16:14:47,28

  Как показала практика работы с Простым Рефалом, вложенные функции существенным образом повышают
выразительность программы и производительность программиста, даже если они и безымянные.
  Кроме того, практика показала, что если синтаксический анализ написан методом рекурсивного спуска
достаточно регулярным образом, то добавить в него вложенные безымянные функции тоже достаточно
несложно.
  Используемый рантайм (общий для Простого Рефала и back-end'а C++/SR Модульного Рефала) поддержи-
вает замыкания (представление вложенных функций во время выполнения программы).
  Версия 0.2 завершена, поэтому ничего не мешает расширению синтаксиса (на который был ранее нало-
жен запрет, дабы сконцентрировать усилия на других задачах).
  Вышеперечисленных аргументов достаточно, чтобы внедрить в язык вложенные безымянные функции
(позже можно будет придумать и именованные). Однако, есть и сложность на этом пути.
  Дело в том, что относительно безболезненно внедрить замыкания только в два профиля из трёх. Ран-
тайм профиля Рефала 5, в отличие от рантайма профилей C++/SR и SR, не поддерживает имманентно замы-
каний и, как следствие, реализация вложенных функций потребует костылей.
  Замыкание представляет собой кортеж, включающий в себя указатель на глобальную функцию и набор
связанных переменных, представляющих собой контекст замыкания. Поэтому задача состоит в том, чтобы
каким-либо образом их хранить в поле зрения. Семантически не должно быть способа разделить замыка-
ние на элементы каким-либо сопоставлением с образцом, следовательно, замыкание должно быть атомом
и сопоставляться с s-переменной.
  Под контеНтом замыкания будем подразумевать кортеж из контеКСта и указателя (имени) глобальной
функции.
  Среди способов реализации замыканий в профиле Рефала 5 можно выделить две группы: надёжные
и ненадёжные.

  I. Простые ненадёжные методы.

  1 При каждом создании замыкания создавать новый уникальный атом (например, функцией Implode),
а контент замыкания помещается в копилку с ключом в виде уникального атома. Непрямой вызов функции
представляется как вызов специальной функции, которая осуществляет проверку наличия уникального
атома в копилке и вызов контента при помощи функции Mu. При отсутствии атома в копилке функцией
Mu вызывается сам атом на входе.
  Недостаток: контенты замыканий не освобождаются, поэтому память будет непрерывно утекать.
  Достоинство: простота.

  2 По аналогии с п. 1, но используется фиксированный пул уникальных атомов. Если же пул опустошён,
то разрушается какое-то замыкание и его атом используется для создания нового замыкания.
  Недостаток: метод невозможно применять на практике, т.к. программа, использующая замыкания,
становится абсолютно ненадёжной — любое замыкание может быть похерено в любой момент.
  Достоинство: относительная простота, отсутствие утечек памяти.
  Метод тут рассматривается только для полноты картины.

  3 По аналогии с п. 1, но с замыканием ассоциируется счётчик вызовов, после которого оно становит-
ся недействительным (соответственно, контент освобождается). Соответственно, при каждом вызове
замыкания счётчик декрементируется.
  Недостаток: необходимо при создании замыкания инициализировать счётчик или специальным синтакси-
сом, или специальной библиотечной функцией, или выбирать значение счётчика по умолчанию. Если при
создании значение счётчика оказалось заниженным, то при "избыточных" вызовах получим ошибку. Если
значение счётчика оказалось заниженным, то память не освободится.
  Достоинство: способ более надёжен, чем п. 2, также способен бороться с утечками памяти.

  4 По аналогии с предыдущим пунктом с замыканием ассоциируется счётчик вызовов, но пользователь
получает возможность управлять этим счётчиком. Например, при создании ассоциируется значение 1,
при копировании замыкания пользователь явно инкрементирует счётчик, при удалении замыкания поль-
зователь должен счётчик явно декрементировать. Фактически, ручной подсчёт ссылок.
  Достоинства: способен обеспечить надёжность программы, а также избежать утечек памяти. Способ
прост. Способ эффективен.
  Недостаток: человеческий фактор. Контроль программиста за копированием напоминает управление
памятью в языках без сборки мусора (например, Си), но здесь последствия не так пагубны. Также недо-
статком является загромождение кода вызовами функций, которые ничего не делают в других профилях.

  II. Сложные надёжные методы. Данные методы всегда обеспечивают надёжность программы и ликвидируют
утечки памяти.

  5 Поскольку циклических связей между замыканиями быть не должно, можно применить подсчёт ссылок.
Т.е. в каждом предложении следует сравнивать количество переменных слева и справа: при уничтожении
переменных следует рекурсивно просматривать удаляемые переменные и декрементировать счётчики, при
копировании — аналогичным способом инкрементировать.
  Достоинство: процесс автоматизирован, надёжен.
  Недостаток: резкое снижение быстродействия.

  6 Изменение формата поля зрения. Атомы можно представлять как (s.Тип e.Значение), скобочные термы
как ((s.Тип e.Значение)). Такой формат позволяет хранить внутри атомов любые объектные выражения,
в том числе и контент замыкания.
  Достоинства: нет нужды в подсчётах ссылок и сборках мусора, утечки памяти невозможны, приличное
быстродействие.
  Недостатки: сравнение одноимённых переменных не за постоянное время, переделка всей библиотеки,
нечитаемость дампов памяти.

  7 Сборка мусора. Идея аналогична п. 2, только при исчерпании пула вызывается сборщик мусора.
  Недостаток: сложность в поддержке корневого множества (не иначе как в п. 5).
  Достоинство: метод надёжный в отличие от п. 2.

  8 Генерация кода в виде CPS (continuation-passing style). В этом случае вместо поля зрения
используется "пассивная" структура данных, в каждый момент времени в реальном поле зрения присут-
ствует только одна скобка конкретизации, поэтому корневое множество поддерживается элементарно.
  Достоинство: корневое множество доступно напрямую.
  Недостаток: это фактически написание нового back-end'а, снижение быстродействия вдвое (на каждый
вызов функции требуется по две скобки конкретизации), сложность кодогенерации.

  9 Эмуляция абстрактной рефал-машины. Можно добиться сравнительно малыми изменениями в кодогене-
рации и в реализации библиотечных модулей.
  Достоинство: доступность корневого множества, простота переделок.
  Недостатки: снижение быстродействия, фактически, написание нового back-end'а.

  Из приемлемых вариантов можно назвать п. 1, п. 4 и п. 9.
----------------------------------------------------------------------------------------------------
  [RENAME] 05.11.2010 - 21:36:08,97

  Old name is "[TODO] ВПВ: Вложенные функции (ВФ)"
  """"""""""""""""""""""""""""""""""""""""""""""""
----------------------------------------------------------------------------------------------------
  [TODO] 05.11.2010 - 21:36:08,97

  Снят префикс ВПВ в связи с тем, что их реализация не входит в приоритеты публичной версии.
  В качестве варианта реализации замыканий для back-end'а Рефала 5 предполагается использовать
модифицированный п. 1, подразумевающий создание нового атома для каждого замыкания, но с явной
операцией уничтожения. Возможна разработка специального модуля аналога MLambda, который вызывает
функцию уничтожения после выполнения требуемой операции. Функция уничтожения замыкания на других
back-end'ах не будет делать ничего.
----------------------------------------------------------------------------------------------------
  [TODO] 06.11.2014 - 12:35:00,01

  Предлагаемый выше вариант вполне работоспособен, однако есть один нюанс. Замыкания могут
содержать внутри себя другие замыкания (например операции MLambda::BindLeft или MLambda::Composite).
Следовательно, явная операция удаления должна удалять замыкания рекурсивно. Но, при этом только
программист знает, когда замыкания удалять нужно, а когда не нужно. В частности, возможен случай,
когда замыкание, после вызова подлежащее удалению, замыкает контекст, содержащий другое замыкание,
пока не подлежащее удалению. Т.е. нужно что-то вроде «деструктора» замыкания.
  Если делать деструктор в соответствии с идиомой ООП, то одно из предложений функции будет
представлять собой метод, левая часть которого должна принимать аргумент, который не могут принимать
другие предложения функции. Недостатки такого подхода:
  1 Невозможно написать замыкание, которое одинаково обрабатывает любой аргумент (частный случай —
деструктор должен будет обрабатываться по особому).
  2 Любое замыкание обязано содержать специальный образец, иначе при удалении замыкания будет
происходить ошибка сопоставления.
  3 В других back-end’ах это предложение не будет иметь смысла, но может (незначительно) снижать
быстродействие.
  Этих трёх проблем можно избежать, если предложение-деструктор сделать синтаксически отличным
от регулярных предложений, например, состоять из одного символа $DELETE. В результатных частях
тот же символ $DELETE может использоваться только как Callable, т.е. после левой скобки
конкретизации. Преимущества:
  1 Выполнить это предложение вызовом <s.Closure $DELETE> невозможно, поскольку синтаксически
некорректно. Единственный способ вызвать это предложение — уничтожить замыкание (вычислив
<$DELETE s.Closure>). Следовательно, данный образец никак не конфликтует с другими образцами.
Следствие: предложение-деструктор может идти любым по счёту: первым, последним…
  2 При отсутствии предложения оно неявно подразумевается с пустой правой частью, т.е. при удалении
замыкания ничего не должно выполняться.
  3 Специальный синтаксис допускает и особый способ компиляции. В других back-end’ах эти предложения
при трансляции будут игнорироваться, равно как будут игнорироваться вызовы <$DELETE …> в правых
частях. Следствие: переносимая программа в предложениях-деструкторах не должна ничего делать, кроме
уничтожения замыканий, захваченных контекстом. Также переносимая программа не должна вкладывать
в вызовы <$DELETE …> вызовы функций с побочным эффектом. Либо, вызовы <$DELETE …> должны
компилироваться в вызовы <NIL …> при наличии скобок конкретизации внутри вызова <$DELETE …>. Такое
поведение снизит быстродействие в корректной программе, но сделает переносимым поведение
в некорректной. Способ трансляции разумно сделать управляемым параметром конфигурации.
  4 Синтаксис Модульного Рефала допускает использование функций с пустым телом, а Рефал-5 — нет.
Приходится для пустых функций добавлять предложение NF = NF (в промежуточном представлении
не существует идентификаторов NF, поэтому такой метод корректен). Использование деструктора
устраняет этот костыль: любая сгенерированная функция будет содержать предложение-деструктор.

  Дополнительные замечания.
  Функция $DELETE соответствует идеологии Модульного Рефала — использование встроенных средств
только для встроенных в язык возможностей.
  Функция $DELETE может принимать не только s-переменную, но и вообще любое объектное выражение,
что имеет смысл, когда замыканий в контексте несколько. Разумеется, передавать литералы атомов
бессмысленно (их даже можно удалять во время компиляции или выдавать предупреждение), но для
унификации синтаксиса допустимо.
  Разрешать ли передачу в $DELETE скобок, как безымянных, так и абстрактных, я пока не определился.
  Конструкции &$DELETE и $DELETE не после левой скобки вызова в результатной части следует считать
ошибочными, равно как и использование $DELETE внутри образца, за исключением образца, состоящего
из единственного символа $DELETE.
  Допустимы два варианта написания $DELETE и $delete.
----------------------------------------------------------------------------------------------------
  [TODO] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  В рамках ревизии комментирую: задача низкоприоритетная, когда будет настроение, ею займусь. Новых
мыслей по ней у меня нет.


====================================================================================================
  [TODO] Ускорение работы компилятора на слабых машинах
====================================================================================================

  [TODO] 27.12.2014 - 15:43:41,16

  На слабых машинах (например, Pentium MMX, 64 Mb RAM) становится очевидным низкое быстродействие
быстродействие компилятора, связанное как с низким быстродействием сгенерированного кода, так и
с неоптимальными алгоритмами в самом компиляторе. К примеру, цикл раскрутки компилятора требует
нескольких десятков минут.
  На момент написания TODO часть работы по оптимизации была выполнена, а именно, были сделаны
следующие выводы и оптимизации.
  * Много времени уходит на создание статистической информации XLinx — около пяти с половиной
минут. Основная причина — отжор виртуальной памяти большей, чем физически установлено на машине.
Компилятор с профилем C++/SR потребляет более 80 Мбайт оперативной памяти, в то время как без свопа
в память влезает не более ≈35 Мбайт (остальное требуется операционной системе и фоновым программам).
Виртуальная память отжиралась по причине трёхкратного копирования перекрёстной информации при
порождении 4 файлов статистики. Двум файлам статистики требовался только список модулей — он стал
формироваться без потребления дополнительной памяти во время прохода по перекрёстной информации;
функция порождения таблицы перекрёстных связей стала прозрачной — в результате копирование
переменной стало ненужным.
  * Другой причиной низкого быстродействия был ассоциативный поиск среди всех записей при
построении инверсных сведений. Было применено хеширование — для каждого имени вычислялся хеш
(число от 0 до 37) и затем применялся двухуровневый ассоциативный поиск (среди имён с данным хешем
и внутри соответствующей корзины). Таким образом сложность была снижена с N² до N*sqrt(N), т.е.
на целый корень. Также хеширование ускорило поиск неслинкованных элементов.
  * Много времени отнимало построение деревьев модулей. Путей модификации логики самого алгоритма
я не обнаружил, а вот изменение структур данных ускорило этот этап примерно вдвое (с ≈40 до ≈20
секунд). Речь идёт о замене имён модулей (e-переменных) на числовые идентификаторы (s-переменнные).
Экономия времени связана со скоростью сравнения на равенство одноимённых переменных.
  * Суммарно эти две оптимизации снизили продолжительность построения статистической информации
до 2 минут.
  * Неплохо ускоряет работу back-end’а C++/SR использование компоновщика на make-файле. При
повторной перекомпиляции даже не запускается компоновщик Си++, т.к. make видит, что исполнимый файл
не обновлён по сравнению с объектными.
  * Перекомпиляция для back-end’а Простого Рефала занимает продолжительное время (порядка 4-5
минут), режимы, ускоряющие его работу, я пока не смотрел, т.к. часто им и не пользовался.
  * Back-end Рефала-5 ещё не оптимизирован, работает сильно медленно (несколько минут), возможно,
его также спасёт хеширование.
  * Профилировщик очень полезен в деле оптимизации.
  * Также полезно наблюдение за работой программы в диспетчере задач Windows XP, т.к. он показывает
не загрузку физической памяти (как в более поздних ОС), а загрузку виртуальной. Визуально по
графикам можно определять причины проблем:
    — если сильно выросло потребление памяти, а загрузка процессора не полная — проблема в свопе;
    — если загрузка процессора полная — проблема в вычислениях.
Сейчас на всём протяжении перекомпиляции имеем практически 100%-ную загрузку процессора.
  * Сейчас уже проблема находится не в свопе, а в затратах на вычисление.
  * Функция MOrder::Sort медленная и путей её ускорения я не вижу.

  Что предстоит сделать:
  * Сделать профилировщики более интеллектуальными. См. отдельное TODO.
  * Рассмотреть вопрос оптимизации кэша. На текущий момент звенья поля зрения в back-end’ах C++/SR
и Простого Рефала имеют размер 5 слов (20 и 40 байт на x86 и amd64 соответственно), что
не оптимально с точки зрения кэша процессора. Каждое звено включает в себя ссылки вперёд и назад
(по 1 слову), поле тега (из-за выравнивания — 1 слово, хотя хватило бы и байта), поле информации
(2 слова).
  Едиственная альтернатива в поле информации, занимающая два слова — ссылка на функцию, включающая
в себя указатель на функцию и указатель на её имя. Если в поле информации хранить не пару
указателей, а указатель на структуру, хранящую эту пару указателей, то звено уже будет кратно строке
кэша. Возможно снижение производительности, связанное с дополнительной косвенной адресацией, но оно
будет пренебрежимо мало по сравнению с затратами времени на всё остальное. Другим преимуществом
будет отход от генерации идентификаторов для представления имён функций в C++/SR.
  * Изыскать пути оптимизации компоновщика back-end’а Простого Рефала.
  * Оптимизировать компоновщик back-end’а Рефала 5, возможно, путём хеширования.
  * Когда исследование совместного сопоставления с образцами будет завершено, внедрить этот механизм
оптимизации.
  
----------------------------------------------------------------------------------------------------
  [TODO] 21.10.2015 - 11:41:49,72

  Из того, что сделано.
  * Профилировщики сделаны интеллектуальными. Соответствующая задача закрыта.

  Из того, что предстоит сделать.
  * Рассмотреть вопрос по оптимизации кэша. Остаётся как есть, см. выше.
  * Изыскать пути оптимизации компоновщика back-end’а Простого Рефала.
  Последние несколько месяцев проект Простого Рефала начал активно развиваться. Применительно
к текущей задаче — быстродействие компилятора заметно повысилось (приблизительно на 5…10 %). Имеет
смысл актуализировать версию Простого Рефала, входящую в проект Модульного Рефала как минимум
из соображений быстродействия.
  См. отдельное TODO.
  * Оптимизировать компоновщик back-end’а Рефала-5. Поиск путей оптимизации пока ведётся. Видятся
два варианта. Эволюционный: ищем в коде узкие места, оптимизируем их. Революционный: отказаться
от переименований функций и переменных на уровне компоновщика, вместо этого просто склеивать файлы.
Правильные имена функций и переменных давать сразу на этапе генерации «объектников».
  См. отдельное TODO.
  * Про совместное сопоставление с образцом. Ничего нового.
----------------------------------------------------------------------------------------------------
  [TODO] 06.11.2015 - 10:21:12,56

  Back-end РЕФАЛа-5 оптимизирован, остальные пункты не потеряли актуальности.
----------------------------------------------------------------------------------------------------
  [TODO] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Что касается оптимизации кэша (4-байтовые узлы), проведено такое исследование для Простого Рефала
(ветка 4bytes не в основной ветке, ветка черновая). Предварительные результаты — снижение
быстродействия на уровне статистической погрешности (около 1 %). Имеет смысл сделать, но только
ради экономии памяти.
  Оптимизация компоновщика профиля Простого Рефала имеет несколько направлений деятельности:
  * оптимизация самого компилятора Простого Рефала,
  * вызов компилятора Простого Рефала только для исходников, изменившихся с момента последней
компиляции.
  Очевидно, первый вариант следует обсуждать не тут, а в трекере самого Простого Рефала, поэтому
заметим, что в ближайшем будущем предстоит исследование некоторых оптимизаций Простого Рефала
в рамках бакалаврских квалификационных работ.
  Второй вариант также возможен и даже имеет больше смысла, ведь при неполной компиляции программы
back-end’ом компилируется весь набор исходников. Устранение избыточной компиляции принесёт большую
пользу, чем ускорение самого Простого Рефала на десятки процентов.


====================================================================================================
  [ERROR] Некорректная обработка двойных кавычек в компоновщике back-end’а РЕФАЛа-5
====================================================================================================

  [ERROR] 06.11.2015 - 12:43:17,75

  Модуль BE-Refal5::MExeTyper, выполняющий формирование целевого файла, неправильно обрабатывает
двойные кавычки. Он не видит разницы между двойными и одинарными кавычками, поэтому может разбивать
текст в кавычках на отдельные строки, склеивать два последовательных закавыченных куска и т. д.
Однако, в современном диалекте РЕФАЛ-5 двойные кавычки не являются синонимом одинарных: они служат
для оформления составных символов.
  Нужно исправить обработку двойных кавычек.
----------------------------------------------------------------------------------------------------
  [ERROR] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Очевидно, задачи актуальности не теряют, хоть ошибки и не критичные.


====================================================================================================
  [TOTHINK] ВПВ: Opensource-лицензия
====================================================================================================

  [TOTHINK] 05.11.2010 - 21:36:08,97

  Следует выбрать opensource-лицензию. TOTHINK станет TODO когда лицензия будет выбрана. TODO
включит в себя задачу по внедрению лицензионного соглашения в исходные тексты программы.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Во-первых, компилятор коммерческой ценности не представляет, но может представлять научную или
программистскую ценность, поэтому для него следует использовать лицензию opensource.
  Во-вторых, из opensource-лицензий я предпочитаю либеральные по типу BSD, чем свободные GNU.
Дело в том, что код под либеральной лицензией можно использовать в рамках проектов под одной
из лицензий *GPL, но наоборот уже нельзя. Кроме того, BSD-лицензии разрешают использовать код
и в несвободном ПО. Таким образом, они налагают меньшее число ограничений.
  Из того, какие лицензии можно использовать. Во-первых, компилятор и библиотеки к языку следует
распространять под разными лицензиями: создание производного продукта на основе компилятора должно
требовать сохранения указания авторских прав в производном продукте, но создание производного
продукта на основе библиотеки (т.е. просто написание программы, использующей библиотеку) не должно
налагать такого ограничения.
  Для компилятора предпочтительны лицензии типа двухпунктовой BSD или MIT (они эквивалентны,
выбор — исключительно вопрос вкуса), для библиотек — «однопунктовая» BSD или Boost. В обоих случаях
распространение библиотек в исходном виде будет требовать сохранения копирайта, в двоичном виде —
нет.
  С конкретным выбором библиотек я пока не определился.
  Для Простого Рефала используется двухпунктовая BSD для компилятора и «однопунктовая» — для
библиотек.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 25.02.2016 - 11:42:56,37

  Временно выбрана двухпунктовая BSD для всего проекта. Лицензия на библиотечные компоненты будет
уточнена, возможно, позаимствована из Простого Рефала.


====================================================================================================
  [TOTHINK] Серьёзное расширение синтаксиса
====================================================================================================

  [TOTHINK] 06.11.2014 - 12:35:00,01

  Обоснование.
  1 Отсутствие вложенных функций приводит как к необходимости явного написания глобальных функций,
затем явно связываемых с контекстом, так и к сложночитаемым комбинациям функций при помощи средств
модуля MLambda ← таково краткое обоснование внедрения в язык хотя бы вложенных безымянных функций.
При этом внедрение в язык только вложенных безымянных функций может привести к похожему результату,
а именно к сложночитаемым комбинациям вложенных безымянных функций (при помощи комбинатора Y,
функций Composite и Fetch). Использование именованных функций полностью обесценивает комбинатор Y,
а соответствующие синтаксические средства снижают потребность в функциях Composite, Fetch и ряде
других. Таким образом, вложенные безымянные функции есть полумера.
  2 Во многих развитых диалектах Рефала есть механизм, позволяющий задавать дополнительные
ограничения на образец в левой части — условия в Рефале-5, неуспехи в других диалектах. Механизм,
очевидно, полезный, однако имитировать его при помощи одних лишь вложенных функций (не важно,
именованных или нет) достаточно трудно (без открытых e-переменных) или даже практически невозможно
(с открытыми e-переменными). Под трудностью и практической невозможностью подразумевается тот факт,
что код в результате получится чрезвычайно сложным и нечитаемым («овчина выделки не стоит»).

  Предлагается реализовать синтаксис, являющийся средним между Рефалом-5 и Рефалом-7: из Рефала-7
берём вложенные функции и действия ":", ",", "->", "::", "=", "=>", из Рефала-5 невозможность
возврата неуспеха из функции. Таким образом, неуспехи могут порождаться только действием ":"
(действие "::" при невозможности сопоставления аварийно останавливает программу), "," и "->"
прозрачны для неуспехов, "=" и "=>" непрозрачны для неуспехов (неперехваченный неуспех после
них приводит к аварийному останову программы), образец после ":" может перехватывать неуспех
(путём удлинения открытых e-переменных), образец после "::" не может перехватывать неуспех
(сопоставление однозначно).
  Вопрос об образцах после "::" (допустимы любые образцы, либо только жёсткие) требует
дополнительной проработки.
  Некоторые переменные могут помечаться как переопределяемые символом "^". Требуют проработки
следующие вопросы: символ "^" должен идти перед переменной или после, если переменная с крышкой
повторная в данном образце, все ли экземпляры должны быть помечены или не все, какие из них.

  В дальнейшем требуется:
  1 Подробнее сформулировать синтаксис и семантику
  2 Проработать указанные выше вопросы
  3 Продумать особенности реализации.
  4 Проанализировать плюсы и минусы возврата неуспехов из функций.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Есть интересные мысли, описывающие довольно цельный, но сложный и громоздкий синтаксис. Их нужно
оформить в виде отдельной спецификации, а также решить, воплощать ли их в программе.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 13.03.2016 - 23:24:12,47

  Предлагается функции делить на три вида (modes):
  1. Чистые функции. Далее — просто функции. Они не могут возвращать неуспех, всегда детерминированы
и не имеют побочных эффектов. Им соответствует символ "&"
  2. Функции, способные вернуть неуспех. Далее — функции-предикаты или просто предикаты. Они чистые,
то есть детерминированы и не имеют побочных эффектов. Им соответствует символ "?".
  3. Недетерминированные функции и/или функции с побочными эффектами. Далее — процедуры (ну не нашёл
другого подходящего слова). Они не могут возвращать неуспех. Им соответствует символ "!".

  Чистые функции могут вызывать только чистые функции и предикаты. При этом, если вызываемые
предикаты возвращают неперехваченный неуспех, происходит аварийное завершение программы. Вызвать
из чистой функции процедуру напрямую синтаксически невозможно, косвенно (по указателю) — приведёт
к тому же авосту во время выполнения.
  Предикаты могут вызывать только чистые функции и другие предикаты. Неперехваченный неуспех
из вызываемого предиката приводит к неуспеху вызывающего предиката. Вызов процедур невозможен
аналогично случаю с чистыми функциями.
  Процедуры могут функции любого вида. Неперехваченный неуспех в процедуре приводит к аварийному
завершению программы.

  Вид функции указывается в объявлении функции:

    &PureFunction {
      …
    }

    PureFunction2 {
      …
    }

    ?Predicate {
      …
    }

    !Procedure {
      …
    }

  При этом у чистых функций знак "&" можно опускать. Вызов функции оформляется аналогично:

    … <&PureFunction …> …
    … <PureFunction2 …> …
    … <?Precicate …> …
    … <!Procedure …> …

    … <& s.FnPureFunction …> …
    … <s.FnPureFunction …> …
    … <? s.FnPrecicate …> …
    … <! s.FnProcedure …> …

  Точно также, в скобках вызова чистой функции знак "&" можно опускать. Последние четыре примера
выше — косвенный запуск. В ряде случаев допустимо косвенно вызывать функцию не того вида, какой
ожидается в вызове — при этом получаем вполне ожидаемое поведение:

    ┌──────────┬───────────────────────────────────────┐
    │          │               Вызов                   │
    │ Функция  ├───────────────────────────────────────┤
    │          │  <& s.Func>   <? s.Func>   <! s.Func> │
    ├──────────┼───────────────────────────────────────┤
    │ &Func    │      ++           ++           ++     │
    │ ?Func    │      +-           ++           +-     │
    │ !Func    │      --           --           ++     │
    └──────────┴───────────────────────────────────────┘

  Обозначения:
  ++ — полностью поддерживается.
  -- — приводит к аварийному останову.
  +- — приводит к аварийному останову при возврате неуспеха вызываемой функции.

  Функция есть набор предложений, синтаксис отдельного предложения:

    Sentence = Pattern { Action }+.
    Action =
        "=" Result
      | "?=" Result
      | "," Result
      | ":" Pattern
      | "::" Pattern
      | "=>" Mode Result
      | "?=>" Mode Result
      | "->" Mode Result
      | Mode "~" Result
      | ( "\&" | "\?" | "\!" ) Pattern Action
      .
    Mode = ( "&" | "?" | "!" ).
    Mode = [ ModeReq ].

  Рассмотрим отдельно каждый из вариантов.
  1. "=" Result — результатное действие, непрозрачное для неуспехов. При возникновении
неперехваченного неуспеха справа от знака "=" происходит аварийный останов программы. Действие
допустимо в любых видах функций.
  2. "?=" Result — результатное действие, способное вернуть неуспех. При возникновении
неперехваченного неуспеха справа от знака "?=", результатом всей функции становится неуспех.
Действие допустимо только в функциях-предикатах.
  3. "," Result — результатное выражение, прозрачное для неуспехов — передаёт неуспех справа-налево.
Действие допустимо в любых видах функций.
  4. ":" Pattern — образцовое действие, способное вернуть неуспех и прозрачное для неуспехов. При
возникновении неуспеха справа от действия, осуществляется поиск нового сопоставления с образцом.
Если удалось сопоставить образец другим образом, выполнение передаётся на следующее действие
предложения. В противном случае действие возвращает неуспех. Действие допустимо в любых видах
функций.
  5. "::" Pattern — перестройка — образцовое действие, прозрачное для неуспехов, но сопоставляющееся
всегда успешно и однозначно. При невозможности сопоставления с образцом программа аварийно
завершается. При возникновении неуспеха справа от действия неуспех передаётся справа-налево.
  6. "=>" @ Result — действие-вызов, непрозрачное для неуспехов. Здесь и ниже @ заменяет "&", "?"
или "!".  Синтаксический сахар. Конструкция
    =>@ R1
эквивалентна следующей конструкции:
    :: e.Env1 = R1 :: e.Env2 = <@ e.Env2 e.Env1>
Действие допустимо в любых видах функций.
  7. "?=>" @ Result — действие-вызов, способное вернуть неуспех. Синтаксический сахар. Конструкция
    ?=>@ R1
эквивалентна следующей конструкции:
    :: e.Env1 ?= R1 :: e.Env2 ?= <@ e.Env2 e.Env1>
Действие допустимо только в функциях-предикатах.
  8. "->" @ Result — действие-вызов, прозрачное для неуспехов. Синтаксический сахар. Конструкция
    ->@ R1
эквивалентна следующей конструкции:
    :: e.Env1, R1 :: e.Env2, <@ e.Env2 e.Env1>
  9. @ "~" Result — действие декаррирования. Прозрачно для неуспехов. Синтаксический сахар.
Конструкция
    @~R1
эквивалентная следующей конструкции:
    :: e.Env1, <@ e.Env1 R1>.
Действие допустимо функциях любых видов.
  10. "\@" Pattern Action — лямбда. Допустима только после результатных действий. Синтаксический
сахар. Конструкция
    … R1 \@ P2 sentence-tail;
эквивалентна
    … R1 @{ P2 sentence-tail; };
Конструкция допустима в любых видах функций. Конструкция может быть полезна для использования в DSL
для каких-нибудь монад или ещё чего-то.

  Вложенные функции могут быть как безымянные, так и именованные. Безымянные имеют вид:
    … &{ … } …
    … { … } …
    … ?{ … } …
    … !{ … } …
Именованные:
    … $func &Pure { … } …
    … $func Pure2 { … } …
    … $func ?Pred { … } …
    … $func !Proc { … } …
Как и ранее, знак "&" допустимо опускать.
  Указатели на глобальные функции представляют собой имена функций, предварённые символом вида:
    FnPtr = ModeReq IDENTIFIER | Mode DotQualifiedName.

  Скобки активации существенно усложнились:

    CallTerm = "<" CallInit { Action } ">".
    CallInit =
        Mode Callable Result
      | "=" Result
      .
    Callable = FunctionName | Variable | CallTerm | FnPtr.
    FunctionName = QuadQualifiedName.

  Смысл здесь в том, что в угловых скобках теперь не просто вызов функции с аргументом-результатным
выражением, а целое предложение, начальный компонент которого — либо вызов функции, либо просто
порождение результата. Список вызываемых объектов теперь включает также все виды переменных, либо
другие скобки вызова — почти всё, что угодно.
  Конструкция "=" Result инициализирует среду значением данного результатного выражения. Таким
образом, запись <= R1> будет эквивалентна просто R1. Смысл конструкции в том, чтобы можно было
писать такие конструкции:
    <=
      <CalcSomething> => {
        Success = …;
        Fails = …;
      }
    >
что эквивалентно идиоме <Fetch …> Простого Рефала:
    <Fetch
      <CalcSomething> {
        Success = …;
        Fails = …;
      }
    >


  Заключение.
  Это описание намеренно сделано нечётким, есть куча неописанных деталей. Причина — это всего лишь
черновик описания. В частности, остаются вопросы:
  1. В ряде мест конфликтуют имена, квалифицированные квадроточием, и перестройки. А не отказаться
ли нам от имён с квадроточиями вообще — перейти на точку? Или можно сделать компилятор
интеллектуальным — догадываться в каждом конкретном случае, что имел ввиду программист. Если
допустимы оба варианта, выдавать ошибку?
  2. Вопрос реализации — надо продумать, как генерить оптимальный код для этих конструкций.
  3. Остался вопрос по перестройкам — должны ли после них быть только жёсткие выражения.
  4. Никак не затронут вопрос переопределения переменных.

  А неуспехи из функций нужны. Они могут существенно поднимать выразительность кода. Но они должны
быть явно синтаксически выделены. Также полезно выделять функции с побочным эффектом. Поэтому как-то
так.
----------------------------------------------------------------------------------------------------
  [TOTHINK] 14.03.2016 -  1:06:36,70

  Дополнительные вопросы:
  5. Синтаксис оказался довольно сложен. Нужно либо обосновать сложность синтаксиса с идеологических
позиций, либо упростить.
  6. Вопрос: можно ли создать в одном модуле несколько функций с одинаковым именем и разными видами?


====================================================================================================
  [TODO] RASL и интерпретатор
====================================================================================================

  [TODO] 29.09.2007 - 20:25:52,85

  Разработать (продумать и реализовать) собственный RASL (Refal Assembly Language) и собственный
интерпретатор, чтобы сделать компилятор независимым от компилятора Рефала-5.
----------------------------------------------------------------------------------------------------
  [TODO] 01.02.2009 - 21:42:25,09

  Использование интерпретируемых файлов на языке сборки (будь то бинарных, будь то текстовых), по-
лезно для переносимости компилятора и программ, т.к. достаточно перенести только интерпретатор.
  Можно на манер SFX-архивов сделать интепретатор, который ищет интепретируемый код в конце самого
исполнимого файла. Если подобный интепретатор перенесён на некоторую платформу X, то это позволит
компилятору самостоятельно (т.е. в полном цикле, не обращаясь затем к другим инструментам для полу-
чения конечного исполнимого файла) создавать самостоятельные приложения (т.е. исполнимые файлы
платформы X, не требующие особого интерпретатора для своего исполнения).
  Эта задача требует много времени и размышнений, если её сделать приоритетной, то выпуск версии
0.2 оттянется на долгий срок.
----------------------------------------------------------------------------------------------------
  [TODO] 01.05.2010 - 19:30:19,45

  (Ревизия 01.05.2010) Не требуется для выпуска версии 0.2.
----------------------------------------------------------------------------------------------------
  [TODO] 25.07.2010 - 12:33:59,02

  Недавно я написал прототип дизассемблера для .rsl-файлов Рефала 5, соответственно, изучил внут-
ренний формат и набор команд этих файлов интерпретируемого кода. В принципе, при разработке собст-
венного RASL'а можно не изобретать велосипед, а расширить имеющийся формат.
  (Ревизия 25.07.2010) Не требуется для выпуска версии 0.2.
----------------------------------------------------------------------------------------------------
  [TODO] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Первоначальная цель создания RASL’а и интерпретатора — отход от использования РЕФАЛа-5,
достигнута иным путём: путём генерации файлов для компилятора C++. Но использование RASL’а полезно
для ухода от C++ — если зафиксировать библиотеку, то можно создавать программы исключительно
средствами компилятора Модульного Рефала.
  В рамках исследований на подопытном Простом Рефале в 2009 и в 2015 году изучалась генерация
интерпретируемого кода, представленного как статический инициализированный массив структур,
описывающих интерпретируемые команды. В 2009 году было реализовано интерпретируемое представление
только для результатных выражений, к тому же представление было довольно неэффективным по памяти
и костылявым по архитектуре (исследование проводилось совместно с Вадимом Сухаревым).
  Исследование 2015 года, выполнявшееся совместно с Игорем Дрогуновым, выполнено гораздо глубже
и качественнее. Достигнут важный результат: если в работе 2009 года в элементы массива команд
передавались не только указатели на функции, но и на локальные переменные, то в последнем
исследовании интерпретируемые команды используют индексы переменных и литеральных значений (функций,
идентификаторов и больших чисел — малые числа хранятся непосредственно в командах). Перейти
от такого представления к непосредственно интерпретируемому коду гораздо проще.
  Создание интерпретируемого кода на основе данного представления и для Простого Рефала будет
продолжено в рамках исследований на Простом Рефале. Причём скорее всего будет исследоваться
и парадигма SFX-архива.
----------------------------------------------------------------------------------------------------
  [TODO] 02.05.2016 - 13:11:50,55

  Если и реализовывать RASL, то не тот, который стихийно образовался в ходе разработки Простого
Рефала, а тот, который предложил Романенко в своей диссертации (1978 года). Он обладает рядом
преимуществ.
  1. Вычислительная модель RASL’а Простого Рефала подразумевает использование множества переменных,
которые соответствуют парам указателей диапазонов, указателям на переменные, указателям
на аллоцированные элементы. Все эти переменные передаются по ссылке в функции рантайма.
  Вычислительная модель RASL’а Романенко проще: пара указателей Г1, Г2 для распознавания,
однородный стек указателей, указатель на вершину этого стека, указатель Г для сборки результатного
выражения.
  В Простом Рефале подобную однородность тоже удалось внести путём замены всех этих переменных
однородный массив указателей context. Но функции рантайма по прежнему берут указатели на элементы
этого массива. Но здесь это надстройка, артефакт, там это уже сразу получается из коробки.
  2. Команды RASL’а Простого Рефала в качестве аргументов получают смещение в context’е (диапазон
при сопоставлении, куда сохранить — при аллокации, откуда брать — при сборке).
  Команды RASL’а Романенко, как правило, безаргументные. Диапазон неявно хранится в регистрах Г1,
Г2, команды аллокации и сборки совмещены — аллоцированный элемент сразу же встаёт на своё место.
  (Понятно, что команды сопоставления с атомами или аллокации элементов должны также принимать
значение соответствующего атома, эти аргументы подразумеваются.)
  Таким образом, RASL Романенко компактнее.
  3. При каждом сопоставлении RASL Романенко сохраняет указатель на вновь сопоставленный элемент.
RASL Простого Рефала не сохраняет — при реализации оптимизации построения результатных выражений
пришлось искусственно внедрять эту возможность.
  4. За исключением циклов по открытым e-переменным, RASL Романенко не изменяет уже присвоенные
указатели — упрощается реализация циклов по e-переменным и оптимизация совместного сопоставления
с образцом — не требуются особые команды сохранения диапазонов.
  Недостаток RASL’а Романенко один — фазы аллокации и сборки результата объединены, это значит,
что при недостатке памяти мы увидим непонятное поле зрения (что и наблюдается в РЕФАЛе-5).


====================================================================================================
  [TODO] Оптимизация совместного сопоставления с образцом
====================================================================================================

  [TOTHINK] 03.05.2012 -  8:09:57,74

  Оптимизация совместного сопоставления с образом состоит в том, что если левые части нескольких
предложений функции имеют много общего (на практике очень распространённый случай - т.н. формат
функции), то имеет смысл сначала сопоставить их общую часть, а затем анализировать только те части,
которыми они различаются. Таким образом можно избежать повторного выполнения одних и тех же опера-
ций: при ошибке сопоставления в общей части мы избегаем повторного анализа похожих образцов, кото-
рые заведомо будут ошибочными, при ошибке сопоставления в специфической части не потребуется пов-
торного анализа общей части.
  Идея эта не нова, поскольку такая оптимизация используется как минимум в Рефале 5 (сгенерирован-
ный код других диалектов я не изучал).
  Недавно (вчера вечером, если быть точным) у меня появилась идея, как можно генерировать подобный
оптимизированный код.
  Чтобы это TOTHINK стало TODO, нужно
  * написать спецификацию, описывающую алгоритм,
  * продумать: стоит ли вместе с этим начать писать новый рантайм для кодогенерации в императивные
языки (в частности, в Си или Си++), или модифицировать C++/SR.
----------------------------------------------------------------------------------------------------
  [TODO] 20.05.2012 - 19:15:12,30

  Спецификацию писать необязательно, поскольку идея крайне проста. Но сначала некоторые общие поло-
жения и некоторые очевидные мысли.
  1. В общую часть могут быть вынесены только жёсткие элементы, сопоставляемые до первой открытой
e-переменной.
  2. В общих частях могут быть связывания переменных со значениями. Поскольку в разных предложениях
на одних и тех же позициях могут быть переменные с разными именами, необходимо вводить сгенерирован-
ные имена, а в дальнейшем внутри самих предложений эти переменные переименовывать.
  3. Механизм "заморозки". В текущей версии кодогенератора много сил требуется на то, чтобы скоррек-
тировать указатели на подвыражения внутри открытых e-переменных: внутри цикла по e-переменной могут
появляться возможности для сопоставления внутри скобочных подвыражений, которые были ранее определе-
ны вне цикла по e-переменной. Если переменные границ скобочных выражений изменятся внутри цикла, но
сопоставление окажется неуспешным, к следующей итерации мы получим неверные указатели на эти грани-
ци. Данная проблема возникнет и при совместном сопоставлении: после сопоставления с общей частью со-
поставление с остатком первого предложения будет изменять указатели на границы, в то время как оста-
ток второго предложения (на который передастся управление в случае ошибки сопоставления в первом ос-
татке) на входе ожидает такие указатели на границы, которые были после сопоставления с общей частью.
  Альтернативой текущему подходу является введение понятия "заморозки". Перед генерацией кода, кото-
рому требуются локальные копии внешних переменных (кода внутри цикла по открытой переменной, остат-
ка предложения) внешние переменные-границы объявляются замороженными: для сопоставления с образцом
с одной из таких границ нужно сначала разморозить данную пару границ, т.е. выбрать новый номер гра-
ницы и присвоить переменным с этим номером значение соответствующих размороженных границ и в ходе
дальнейшего сопоставления использовать новый номер переменных-границ.

  А теперь основная идея, которая кажется очевидной, но когда она ко мне пришла, я почувствовал оза-
рение. В текущей версии генератора псевдокода команда создаётся сразу, как только она обнаруживает-
ся, а затем цикл повторяется. Для обнаружения общего кода алгоритм следует модифицировать следующим
образом:
  1. Рассматривается группа предложений, для которых генерируется алгоритм совместного сопоставле-
ния. Изначально этой группой являются все предложения данной функции.
  2. Если в группе только одно предложение, то генерация алгоритма осуществляется известным спосо-
бом. В противном случае следует выполнять нижеследующие шаги.
  3. Сначала обнаружить все возможные операции сопоставления, доступные в текущей конфигурации (кон-
фигурацию при этом не изменять) для каждого из предложений группы. Доступными являются сопоставления
с жёсткими элементами и определения закрытых e-переменных.
  4. Среди множеств доступных операций сопоставления выбрать ту, которая является общей для наиболь-
шего числа предложений.
  5. Если выбранная операция применима ко всем предложениям группы, то сформировать эту операцию как
команду сопоставления, общую для группы. Применить операцию к конфигурациям предложений группы. Про-
должить формировать команды сопоставления для группы, как описано в пункте 3.
  6. Если выбранная операция применима только к части предложений группы, то сформировать из этих
предложений новую группу, для которой генерировать код, заморозив все определённые ранее границы.
Выбранная операция будет применима ко всем предложениям новой группы, т.е. для этой группы будет
применим пункт 5. Из остальных предложений сформировать другую группу, которую следует обрабатывать
начиная с пунка 2. (Следует помнить, что как первая новая группа, так и вторая могут состоять един-
ственного предложения).

  Вторым пунктом TOTHINK было обдумывание вопроса: следует ли создавать новый рантайм для этой опти-
мизации. Ответ: не нужно, поскольку генерация оптимизированного кода достижима и в рамках текущего
рантайма, возможно, расширив его новыми командами.
  Например, для функции
  F {
    A t.X (e.Y) e.Z = X;
    B t.X (e.Y) e.Z = Y;
  }
при оперировании только имеющимися командами, не удастся выявить общий код, поскольку команды сопо-
ставления с именами A и B будут разными, после которых оба предложения попадут в разные группы. Ре-
шением данной проблемы будет генерация сопоставления с неявной s-переменной, значение которой срав-
нивается с именами A и B. Другой, более оптимальный, алгоритм — сопоставление с неизвестным иденти-
фикатором (сравнивается только тег типа), затем сравнивать только значение этого идентификатора,
вариант возможно потребует большего количества изменений рантайма.
----------------------------------------------------------------------------------------------------
  [TODO] 14.07.2012 - 11:51:13,55

  Алгоритм в той форме, в которой он описан, не будет сохранять семантику исходной функции.
Например:
  F {
    X A e.X = R1;
    e.X Y = R2;
    X B e.X = R3;
    X e.X = R4;
  }
  В этом примере наиболее общей операцией будет отщепление элемента X слева, и, таким образом,
предложения 1, 3 и 4 попадут в одну группу, которая будет перехватывать все случаи, когда аргумент
начинается с X. Но семантика такой функции изменится: если аргумент начинается на X, после которого
не следует A, и заканчивается на Y будет перехвачен третьим или четвёртым предложением, в то время
как в неоптимизированной функции выполнилось бы второе предложение.
  Проблема в том, что группировка предложений по общей операции сопоставления меняет их относитель-
ный порядок, что, в случаях, когда один и тот же аргумент может соответствовать разным образцам,
способно привести к изменению семантики. Прямолинейная группировка возможна только для тех случаев,
когда образцы ортогональны.
  Допустимо, и вполне логично, рассматривать образцы как предикаты, возвращающие истину или ложь
для некоторого аргумента. Кроме того, их можно представить в виде конъюнкции более простых
предикатов, которые соответствуют т.н. линейным образцам — без открытых e-переменных и повторных
переменных (некий терм равен литералу, терм является скобочным, i-й терм слева или справа доступен,
т.е. возможно его отщепить, выражение содержит ровно n термов и т.д.), и сложных (два терма равны,
подвыражение справа/слева начинается с некоторого другого подвыражения, два подвыражения равны,
подвыражение где-то внутри содержит цепочку термов (сканирование по открытой e-переменной) и т.д.).
  Для ссылок на отдельные термы и подвыражения в скобках можно ввести понятие пути:
  — путь к выражению верхнего уровня есть пустая строка,
  — путь к подвыражению в скобках равен пути к скобочному терму,
  — путь к терму, находящемуся в i-й позиции подвыражения se слева или справа имеет вид, соответ-
ственно seLi и seRi.
  Например, для образца (t.1 (t.2) e t.3 (t.4 t.5)) e t.6 пути к термам t.1 t.2 t.3 t.4 t.5 t.6
имеют вид, соответственно, L1L1, L1L2L1 или L1L2R1, L1R2, L1R1L1 или L1R1R2, L1R1L2 или L1R1R1, R1.
  Предикаты, соответствующие элементарным операциям отсечения терма слева (сопоставления с t e)
и справа (сопоставления с e t), будем обозначать как ^…Li и ^…Ri, тогда сопоставление с пустым
выражением можно будет обозначить как !^…Li и как !^…Ri.
  Образцы фиксированной длины можно выразить несколькими разными логическими выражениями, что
означает возможность генерации алгоритма сопоставления с образцом разными способами. Для простоты
ниже такие случаи рассматривать не будем.
  Предикативное представление может быть полезным для различных теоретических изысканий. Например,
приведение набора образцов к ортогональной форме. Обозначим Pi — i-й образец. Условие ортогонально-
сти имеет вид Pi & Pj == false для i ≠ j. Можно показать, что если заменить предикаты Pi, соответ-
свующие i-м предложениям, на предикаты P'i = !P1 & !P2 & … & !Pi-1 & Pi, то семантика функции
не изменится, однако образцы (предикаты) станут ортогональными. Поскольку предикаты представляются
в конъюнктивной форме, то отрицание предиката будет представлять собой дизъюнкцию отрицаний
отдельных команд сопоставления. Перемножение этой суммы отрицаний на предикат Pi, возможно, приве-
дёт к его размножению, т.е. при переходе от предикативной записи обратно к образцовой (см. пример
ниже) мы получим набор предложений вместо одного исходного. Можно показать, что получившийся набор
образцов станет ортогональным. Действительно, пусть i > j. Тогда P'i & P'j = (!P1 & … & !Pj & …
… & Pi) & (!P1 & … & Pj) == false. Пусть P'i = (A | B), P'j = (C | D). Тогда (A | B) & (C | D) ==
== false → A & C | B & C | A & D | B & D == false → A & C == false, B & C == false, A & D == false,
B & D == false.
  Рассмотрим пример:
  G {
    X e.1 = R1;     → P1 = ^L1 & (L1 == X)
    e.1 Y = R2;     → P2 = ^R1 & (R1 == Y)
  }
  Образцы в ортогональной форме:
  P'1 = P1,
  P'2 = !P1 & P2 = !^L1 & ^R1 & (R1 == Y) | ^L1 & (L1 ≠ X) & ^R1 & (R1 == Y).
  После преобразования функция приобретает вид:
  G' {
    X e.1 = R1;
    Y = R2;
    ~X e.1 Y = R2;
  }
  Здесь ~X означает любой терм, не равный X. Очевидно, что преобразованная функция в отличие
от исходной, не чувствительна к перестановке предложений. Для аргумента X Y всегда будет выполнено
первое предложение.
  Также можно показать, что если одному из образцов предшествует более общий образец, то вычисление
ортогонального образца даст false, т.е. пустое множество набора ортогональных образцов. В таких
случаях разумнее всего давать предупреждение компилятора.
  Для вычисления набора ортогональных образцов можно не пользоваться напрямую предикативным
представлением, а осуществлять операции умножения на отрицание выражения, алгоритм будет в целом
похож на алгоритм вычисления объединения двух образцов — см. соответствующую «лабу».

  Недостаток подхода через ортогонализацию заключается в том, что количество образцов резко
увеличивается и каждый из них усложняется. Поэтому будем использовать другой подход, который
назовём частичной группировкой. Рассмотрим пример:
  H {
    X A e.X = R1;
    X B e.X = R2;
    e.X C = R3;
    X D e.X = R4;
    X F e.X = R5;
  }
  Исходный алгоритм здесь предложил бы сгруппировать все предложения, кроме третьего по признаку,
что все они начинаются на X. Однако, как уже было сказано, образцы неортогональны и это приведёт
к изменению семантики (два предложения снизу неявно ожидают, что последний терм не равен C).
  Поэтому группировать следует по общему признаку до тех пор, пока не встретим обобщение в данной
позиции. В данном случае обобщением будет e…, поскольку X… уже, чем e…. Группировать мы можем
только среди сопоставлений, имеющих одинаковую «ширину», т.е. среди тех сопоставлений, что никакое
из них не имеет более широкую область сопоставления, чем остальные.
  Введём дополнительные определения
  Ортогональным набором будем называть набор последовательных образцов, имеющих в некоторой позиции
только сопоставления одинаковой «ширины».
  Ортогональный набор определяется для некоторой позиции, в которой происходит сопоставление.
При выборе другой позиции мы можем получить другой ортогональный набор.
  Можно выделить следующие разновидности ортогональных наборов.
  1. Литеральные значения атомов + скобочные термы + сопоставления с пустыми выражениями. Такой
ортогональный набор завершается любой переменной, не важно, повторной или новой (последнее включает
также открытые и закрытые e-пермененные). Можно менять порядок любых образцов, различающихся
в данной позиции. Можно группировать термы, имеющие одинаковую операцию сопоставления в данной
позиции (разумеется, с сохранением относительного порядка внутри группы).
  2. Повторные s-переменные + скобочные термы + сопоставления с пустыми выражениями. Такой набор
завершается новой s-переменной, любой t- или e- переменной. Поскольку значения повторных
s-переменных нам не известны, мы не можем менять относительный порядок этих образцов. Таким
образом, группировка по операции сопоставления не должна учитывать то, что повторные переменные
могут быть равны разным переменным.
  3. Новые s-переменные + скобочные термы + сопоставления с пустыми выражениями. Такой набор
завершается любой t- или e- переменной. Группируются по виду операции сопоставления обычным образом.
  4. Любые атомарные значения (литералы, любые s-переменные) + скобочные термы + сопоставления
с пустыми выражениями. Завершается любой t- или e-переменной. Нельзя менять относительный порядок
образцов, различающихся любым атомарным значением.
  5. Известные термовые значения (атомарные литералы, повторные s- и t-переменные, скобочные
термы) + сопоставления с пустыми выражениями. Завершаются новой s- или t-переменной, любой
e-переменной. Относительный порядок сопоставления с термовыми значениями менять нельзя.
  6. Ограниченные термовые значения (атомарные литералы, любые s-переменные, повторные
t-переменные, скобочные термы) + сопоставления с пустыми выражениями. Завершаются новой
t-переменной, любой e-переменной. Относительный порядок сопоставления с ограниченными термовыми
значениями нельзя.
  7. Любые термовые значения (атомарные литералы, любые s- и t- переменные) + сопоставления
с пустыми выражениями. Завершаются любой e-переменной. Относительный порядок термовых значений
менять нельзя.
  (8.) Любые сложные образцы кроме закрытых e-переменных. Завершается закрытой e-переменной.
Добавлен здесь, разумеется, для полноты картины, практического смысла не имеет.
  Примечание. «Завершающие» команды сопоставления не входят в ортогональный набор, а следуют
непосредственно за ним. Элементы, разделённые знаком «+», могут быть объединены в группы
с общей операцией сопоставления.
  Примечание 2. В списке отстутствуют АТД-термы, но схему можно обобщить и на них.
  Некоторые виды ортогональных наборов могут включать в  себя несколько более мелких ортогональных
наборов. Например, несколько образцов, образующих первую разновидность, могут входить в более
длинный набор шестой разновидности.

  Очевидно, система оказалась слишком сложной, и связано это с тем, что элементарные команды
сами по себе сложны. Введём альтернативный набор команд — от поддиапазона будем отщеплять только
термы (условно, t-переменные), которые затем уже анализируются отдельно (терм есть атом, равный
данному литералу, просто атом (s-переменная), повторная переменная, скобочный (АТД) терм).
С одной стороны ортогональность команд существенно повышается (нет отдельных команд для
сопоставления с термом определённого вида слева/справа), с другой возможна потеря производи-
тельности — терм анализируется дважды — во время отсечения терма (для скобочного терма нужно
перепрыгнуть по скобке, для остальных просто сдвинуться), а затем проанализировать отсечённый
терм отдельно. Однако, есть надежда, что эффект от совместного сопоставления превысит вышеупомя-
нутые потери.
  Тогда можно будет ввести следующую классификацию ортогональных наборов.
  1. Ортогональные наборы для краёв подвыражений.
  1.1 Жёсткие элементы (термы и повторные e-переменные) и сопоставления с пустым выражением.
Ограничение — открытые и повторные e-переменные. Никакие команды тут переупорядочивать нельзя.
Данный вид введён лишь для полноты картины, практического интереса не представляет.
  1.2 Термы + сопоставления с пустым выражением. Ограничиваются любой e-переменной. Естественным
образом образцы разбиваются на две ортогональные группы: отсечение терма от непустого выражения
и выражение пустое. Если среди представленных образцов есть представители обоих групп, то код
можно генерировать в виде конструкции if-else.
  2. Ортогональные наборы для термов.
  2.1 Терм является известным (повторная переменная, литерал, скобочный или АТД-терм). Ограничение
— t-переменная. Как и для краёв подвыражений, это случай рассмотрен для полноты картины, применения
ему я пока не вижу.
  2.2 Литеральные атомарные значения + скобочные (АТД) термы. Ограничение — любая переменная.
Группировка, очевидно, по литеральным значениям, по виду и меткам скобок.
  2.3 Новые s-переменные + скобочные (АТД) термы. Ограничение — повторная s-переменная, любая
t-переменная. Группируются по атомарности, виду и меткам скобок.
  2.4 Атомарные термы (любые s-переменные и литеральные значения) + скобочные (АТД) термы.
Ограничение — любая t-переменная. Группируются по атомарности, виду и меткам скобок.
  3. Ортогональные наборы для атомарных термов.
  3.1 Терм является известным (повторная s-переменная, литерал). Ограничение — новая s-переменная.
  3.2 Терм является литеральным значением. Ограничение — любая s-переменная. Возможна группировка
по значениям: числа, идентификаторы, characters, указатели на функции и т.д.
  Для некоторых позиций группы образцов возможно найти различные разновидности ортогональных
наборов. Например, последовательность 2.2 может входить в последовательность 2.4. Задача алгоритма
оптимизации найти наибольший ортогональный набор. Тогда если одна и та же последовательность
является наибольшим ортогональным набором, подходящим под определения 2.2 и 2.4, то её следует
рассматривать как более узкий вариант 2.2, чем как 2.4, поскольку последний подразумевает лишний
уровень косвенности — дополнительную проверку на атомарность, чтобы отсечь все атомы к группе 3.
Если же последовательность, подходящая под 2.2 короче, чем под 2.4, то следует наоборот применять
последний.
----------------------------------------------------------------------------------------------------
  [TODO] 06.11.2014 - 12:35:00,01

  На данный момент этим исследованием занимается студент ИУ-9 Батусов Павел в рамках своего
курсового проекта. По завершении проекта будет готова расчётно-пояснительная записка с обоснованием
корректности алгоритма, а также оптимизирующий компилятор Простого Рефала. Записка будет включена
в настоящий репозиторий, а алгоритм оптимизации внедрён в Модульный Рефал (что сделать несложно
ввиду сходства языков).
----------------------------------------------------------------------------------------------------
  [TODO] 06.11.2015 - 12:43:17,75

  Исследование сопоставления, сделанное Батусовым, завершилось ничем с практической точки зрения.
Из несомненных результатов — была сформулирована теория обобщений образцов, но на практике её
проверить не удалось. Возмжно, в дальнейшем оно будет реализовано как положено.

  Лучшее — враг хорошего. Следует продумать вариант, используемый в компиляторе РЕФАЛ-5: оптимизация
на уровне промежуточного кода. Для каждого предложения промежуточный код генерируется независимо,
затем из последовательностей команд сопоставления отдельных предложений генерируем дерево. Этот
вариант не будет давать идеальный результат (который мог бы давать алгоритм, построенный
на вычислении обобщений образцов), но с практической точки зрения он будет давать вполне приемлемое
ускорение.

  На данный момент, при выполнении полной пересборки в профиль C++/SR с заглушкой rem в качестве
компилятора C++ 16 % времени выполнения программы тратится на линейную часть сопоставления
с образцами — это время без учёта повторных переменных и циклов по открытым переменным. Эта метрика
идёт третьей строчкой после внешних функций (29 %) и линейного времени построения результатных
выражений (22 %).
  Таким образом, данная оптимизация не сможет дать выигрыш в быстродействии более чем 16 % в силу
того, что остальное время занимают операции, не затрагиваемые оптимизацией.
----------------------------------------------------------------------------------------------------
  [TODO] 18.12.2015 - 16:11:11,60

  (Ревизия 18.12.2015)
  Во-первых, на следующее полугодие планируется развить исследование совместного сопоставления
с образцом, начатое Павлом Батусовым, но уже с другим студентом (Иван Скрыпников) и в рамках
квалификационной работы бакалавра. Работа над этой задачей будет продолжена после завершения этого
исследования.
  Во-вторых, пара замечаний об оптимизации с построением дерева. (а) Недостаток этого алгоритма
в том, что если два предложения, имеющие общую структуру, случайно различаются только первой
командой сопоставления, то общий префикс обнаружен не будет. Таким образом, метод не выделяет даже
ЛСО. (б) Метод построения дерева хорош для RASL’а, описанного в диссертации Романенко (197? год),
в моём случае придётся генерировать кучу команд сохранения скобок, тут будет та же проблема, что
и для открытых e-переменных (команды сопоставления скобок успешно генерируются в Простом Рефале,
но ещё не реализованы в Модульном).
  Но по данному пункту всё равно есть работа. Когда-то начиналась работа по внедрению оптимизации,
но она заглохла на полпути. Из-за этого код построения «алгоритма» и сишного кода испортился.
Имеет смысл провести рефакторинг кода, а также исправить ошибку удлинения открытых e-переменных.
----------------------------------------------------------------------------------------------------
  [TODO] 02.05.2016 - 13:11:50,55

  Циклы удлинения e-переменных исправлены.
  Заготовки для оптимизации совместного сопоставнения с образцом удалены.


